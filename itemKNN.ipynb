{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import surprise\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import PredefinedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40748</td>\n",
       "      <td>9926</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35757</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18266</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31006</td>\n",
       "      <td>8795</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68084</td>\n",
       "      <td>14837</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0    40748     9926      -1\n",
       "1    35757       79      10\n",
       "2    18266       51      -1\n",
       "3    31006     8795       7\n",
       "4    68084    14837       8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING: Only run once or data will be lost\n",
    "\n",
    "# Instance datasets\n",
    "train_file = pd.read_csv('dataset/train.csv', sep=',', header=0)\n",
    "test_file = pd.read_csv('dataset/validation.csv', sep=',', header=0)\n",
    "anime_file = pd.read_csv('dataset/anime.csv', sep=',', header=0)\n",
    "\n",
    "train_file.to_csv(\"dataset/train.csv\", index=False, header=False)  # Remove 1st row from CSV\n",
    "test_file.to_csv(\"dataset/validation.csv\", index=False, header=False)\n",
    "anime_file.to_csv(\"dataset/anime.csv\", index=False, header=False)\n",
    "\n",
    "train_file = pd.read_csv('dataset/train.csv', names = ['user_id','item_id','rating'] ,sep=',', header=None) \n",
    "test_file = pd.read_csv('dataset/validation.csv', names = ['user_id','item_id','rating'], sep=',', header=None)\n",
    "anime_file = pd.read_csv('dataset/anime.csv', names = ['anime_id','name','genre','type','episodes','rating','members'], sep=',', header=None)\n",
    "\n",
    "train_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data \n",
    "reader = surprise.Reader(line_format='user item rating', sep=',', rating_scale=(1,10))\n",
    "data = surprise.Dataset.load_from_folds([(\"dataset/train.csv\", \"dataset/validation.csv\")], reader=reader)\n",
    "pkf = PredefinedKFold()\n",
    "trainset, testset = next(pkf.split(data))\n",
    "a_testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x124b47b50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myItemKnn = surprise.KNNBasic(k=7, sim_options={'name': 'pearson', 'user_based': False})\n",
    "myItemKnn.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = myItemKnn.test(a_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0162\n",
      "0.016166101738789324\n"
     ]
    }
   ],
   "source": [
    "RMSE_VALUE = accuracy.rmse(predictions)\n",
    "print(RMSE_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check in depth these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid='40748', iid='79', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'}), Prediction(uid='40748', iid='51', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'}), Prediction(uid='40748', iid='8795', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'}), Prediction(uid='40748', iid='14837', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'}), Prediction(uid='40748', iid='1536', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'})]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid='31006', iid='1239', r_ui=6.165656934306569, est=6.0, details={'actual_k': 1, 'was_impossible': False}), Prediction(uid='46414', iid='20159', r_ui=6.165656934306569, est=5.0, details={'actual_k': 1, 'was_impossible': False}), Prediction(uid='67409', iid='8675', r_ui=6.165656934306569, est=7.0, details={'actual_k': 1, 'was_impossible': False}), Prediction(uid='32545', iid='31737', r_ui=6.165656934306569, est=7.0, details={'actual_k': 1, 'was_impossible': False}), Prediction(uid='70120', iid='27899', r_ui=6.165656934306569, est=7.0, details={'actual_k': 1, 'was_impossible': False})]\n"
     ]
    }
   ],
   "source": [
    "valid_predictions = [pred for pred in predictions if not pred.details['was_impossible']]\n",
    "print(valid_predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid predictions: 2086\n",
      "All predictions: 78455796\n",
      "rate: 2.6588220454738615e-05\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valid predictions: {len(valid_predictions)}\")\n",
    "print(f\"All predictions: {len(predictions)}\")\n",
    "print(f\"rate: {len(valid_predictions) / len(predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the situation with UserKNN happened again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now analize a top 10 generated list via predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('9926', 6.165656934306569), ('79', 6.165656934306569), ('51', 6.165656934306569), ('14837', 6.165656934306569), ('1536', 6.165656934306569), ('1241', 6.165656934306569), ('8668', 6.165656934306569), ('6325', 6.165656934306569), ('1887', 6.165656934306569), ('258', 6.165656934306569)]\n"
     ]
    }
   ],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Devuelve las N-mejores recomendaciones para cada usuario de un set de predicción.\n",
    "\n",
    "    Args:\n",
    "        predictions(lista de objetos Prediction): La lista de predicción obtenida del método test.\n",
    "        n(int): El número de recomendaciónes por usuario\n",
    "\n",
    "    Returns:\n",
    "    Un diccionario donde las llaves son ids de usuario y los valores son listas de tuplas:\n",
    "        [(item id, rating estimation), ...] de tamaño n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "# Predict top 10 ratings of user 31006\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "print(top_n[\"31006\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    predicted = predicted[:k]\n",
    "    score = 0.0\n",
    "    hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            hits += 1.0\n",
    "            score += hits / (i + 1.0)\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual_dict, predicted_dict, k=10):\n",
    "    return np.mean([apk(actual_dict[u], [iid for iid, _ in predicted_dict[u]], k) for u in predicted_dict if u in actual_dict])\n",
    "\n",
    "def ndcg_at_k(actual_dict, predicted_dict, k=10):\n",
    "    def dcg(relevance_scores):\n",
    "        return sum([rel / np.log2(idx + 2) for idx, rel in enumerate(relevance_scores)])\n",
    "\n",
    "    scores = []\n",
    "    for u in predicted_dict:\n",
    "        if u not in actual_dict:\n",
    "            continue\n",
    "        pred_items = [iid for iid, _ in predicted_dict[u][:k]]\n",
    "        actual_items = actual_dict[u]\n",
    "        relevance = [1 if iid in actual_items else 0 for iid in pred_items]\n",
    "        ideal_relevance = sorted(relevance, reverse=True)\n",
    "        if dcg(ideal_relevance) == 0:\n",
    "            scores.append(0.0)\n",
    "        else:\n",
    "            scores.append(dcg(relevance) / dcg(ideal_relevance))\n",
    "    return np.mean(scores)\n",
    "\n",
    "def recall_at_k(actual_dict, predicted_dict, k=10):\n",
    "    recalls = []\n",
    "    for u in predicted_dict:\n",
    "        if u not in actual_dict:\n",
    "            continue\n",
    "        pred_items = [iid for iid, _ in predicted_dict[u][:k]]\n",
    "        actual_items = actual_dict[u]\n",
    "        if not actual_items:\n",
    "            continue\n",
    "        hit_count = len(set(pred_items) & actual_items)\n",
    "        recalls.append(hit_count / len(actual_items))\n",
    "    return np.mean(recalls)\n",
    "\n",
    "def diversity(top_n, sim_matrix):\n",
    "    diversities = []\n",
    "    for user, recs in top_n.items():\n",
    "        sims = []\n",
    "        items = [iid for iid, _ in recs]\n",
    "        for i in range(len(items)):\n",
    "            for j in range(i+1, len(items)):\n",
    "                sims.append(sim_matrix[items[i]].get(items[j], 0))\n",
    "        if sims:\n",
    "            diversities.append(1 - np.mean(sims))\n",
    "    return np.mean(diversities)\n",
    "\n",
    "def calculate_novelty(top_n, item_popularity, total_items):\n",
    "    novelty_scores = []\n",
    "    for user, recs in top_n.items():\n",
    "        for iid, _ in recs:\n",
    "            freq = item_popularity.get(iid, 1)\n",
    "            novelty_scores.append(np.log2(total_items / freq))  \n",
    "    return np.mean(novelty_scores)\n",
    "\n",
    "true_items = defaultdict(set)\n",
    "for uid, iid, true_r in testset:\n",
    "    true_items[uid].add(iid)\n",
    "\n",
    "total_items = train_file['item_id'].nunique()\n",
    "\n",
    "item_popularity = defaultdict(int)\n",
    "for _, iid, _ in trainset.all_ratings():\n",
    "    raw_iid = trainset.to_raw_iid(iid)\n",
    "    item_popularity[raw_iid] += 1\n",
    "\n",
    "sim_matrix = defaultdict(dict)\n",
    "for inner_iid1 in range(len(myItemKnn.sim)):\n",
    "    raw_iid1 = trainset.to_raw_iid(inner_iid1)\n",
    "    for inner_iid2 in range(len(myItemKnn.sim[inner_iid1])):\n",
    "        raw_iid2 = trainset.to_raw_iid(inner_iid2)\n",
    "        sim_matrix[raw_iid1][raw_iid2] = myItemKnn.sim[inner_iid1][inner_iid2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.0010\n",
      "NDCG@10: 0.0019\n",
      "Recall@10: 0.0037\n",
      "Diversity: 1.0000\n",
      "Novelty: 8.4038\n"
     ]
    }
   ],
   "source": [
    "map_score = mapk(true_items, top_n, k=10)\n",
    "ndcg_score = ndcg_at_k(true_items, top_n, k=10)\n",
    "recall_score = recall_at_k(true_items, top_n, k=10)\n",
    "div_score = diversity(top_n, sim_matrix)\n",
    "nov_score = calculate_novelty(top_n, item_popularity, total_items)\n",
    "\n",
    "print(f\"MAP@10: {map_score:.4f}\")\n",
    "print(f\"NDCG@10: {ndcg_score:.4f}\")\n",
    "print(f\"Recall@10: {recall_score:.4f}\")\n",
    "print(f\"Diversity: {div_score:.4f}\")\n",
    "print(f\"Novelty: {nov_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to modify the parameters to have more valid predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "myItemKnn = surprise.KNNBasic(k=5, sim_options={'name': 'cosine', 'user_based': False})\n",
    "myItemKnn.fit(trainset)\n",
    "predictions = myItemKnn.test(a_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid='40748', iid='79', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'}), Prediction(uid='40748', iid='51', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'}), Prediction(uid='40748', iid='8795', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'}), Prediction(uid='40748', iid='14837', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'}), Prediction(uid='40748', iid='1536', r_ui=6.165656934306569, est=6.165656934306569, details={'was_impossible': True, 'reason': 'Not enough neighbors.'})]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid='40748', iid='2904', r_ui=6.165656934306569, est=1, details={'actual_k': 1, 'was_impossible': False}), Prediction(uid='40748', iid='10702', r_ui=6.165656934306569, est=1, details={'actual_k': 1, 'was_impossible': False}), Prediction(uid='35757', iid='6045', r_ui=6.165656934306569, est=10, details={'actual_k': 1, 'was_impossible': False}), Prediction(uid='35757', iid='3652', r_ui=6.165656934306569, est=10, details={'actual_k': 1, 'was_impossible': False}), Prediction(uid='35757', iid='6746', r_ui=6.165656934306569, est=10, details={'actual_k': 1, 'was_impossible': False})]\n"
     ]
    }
   ],
   "source": [
    "valid_predictions = [pred for pred in predictions if not pred.details['was_impossible']]\n",
    "print(valid_predictions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid predictions: 373449\n",
      "All predictions: 78455796\n",
      "rate: 0.004759992493097642\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valid predictions: {len(valid_predictions)}\")\n",
    "print(f\"All predictions: {len(predictions)}\")\n",
    "print(f\"rate: {len(valid_predictions) / len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.2124\n",
      "0.21242250627319215\n"
     ]
    }
   ],
   "source": [
    "RMSE_VALUE = accuracy.rmse(predictions)\n",
    "print(RMSE_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('986', 7.0), ('1303', 7.0), ('849', 7.0), ('3702', 7.0), ('433', 7.0), ('3791', 7.0), ('16355', 7.0), ('5204', 7.0), ('9926', 6.165656934306569), ('79', 6.165656934306569)]\n"
     ]
    }
   ],
   "source": [
    "# Predict top 10 ratings of user 31006\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "print(top_n[\"31006\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.0014\n",
      "NDCG@10: 0.0027\n",
      "Recall@10: 0.0052\n",
      "Diversity: 0.9995\n",
      "Novelty: 7.9690\n"
     ]
    }
   ],
   "source": [
    "map_score = mapk(true_items, top_n, k=10)\n",
    "ndcg_score = ndcg_at_k(true_items, top_n, k=10)\n",
    "recall_score = recall_at_k(true_items, top_n, k=10)\n",
    "div_score = diversity(top_n, sim_matrix)\n",
    "nov_score = calculate_novelty(top_n, item_popularity, total_items)\n",
    "\n",
    "print(f\"MAP@10: {map_score:.4f}\")\n",
    "print(f\"NDCG@10: {ndcg_score:.4f}\")\n",
    "print(f\"Recall@10: {recall_score:.4f}\")\n",
    "print(f\"Diversity: {div_score:.4f}\")\n",
    "print(f\"Novelty: {nov_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
