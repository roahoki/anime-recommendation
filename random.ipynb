{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import random\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40748</td>\n",
       "      <td>9926</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35757</td>\n",
       "      <td>79</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18266</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31006</td>\n",
       "      <td>8795</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68084</td>\n",
       "      <td>14837</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0    40748     9926      -1\n",
       "1    35757       79      10\n",
       "2    18266       51      -1\n",
       "3    31006     8795       7\n",
       "4    68084    14837       8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv',\n",
    "                         sep=',',\n",
    "                         names = ['user_id','item_id','rating'],\n",
    "                         header=0)\n",
    "\n",
    "df_items = pd.read_csv('dataset/anime.csv',\n",
    "                        sep=',',\n",
    "                        names = ['anime_id','name','genre','type','episodes','rating','members'],\n",
    "                        header=0)\n",
    "\n",
    "df_test = pd.read_csv('dataset/validation.csv',\n",
    "                        sep=',',\n",
    "                        names = ['user_id','item_id','rating'],\n",
    "                        header=0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = df_train['user_id'].unique()\n",
    "unique_item_ids = df_train['item_id'].unique()\n",
    "\n",
    "user_id_map = {uid: idx for idx, uid in enumerate(unique_user_ids)}\n",
    "item_id_map = {iid: idx for idx, iid in enumerate(unique_item_ids)}\n",
    "reverse_item_id_map = {idx: iid for iid, idx in item_id_map.items()} \n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "\n",
    "for row in df_train.itertuples(index=False):\n",
    "    user_idx = user_id_map[row.user_id]\n",
    "    item_idx = item_id_map[row.item_id]\n",
    "\n",
    "    rows.append(user_idx)\n",
    "    cols.append(item_idx)\n",
    "    data.append(1)\n",
    "\n",
    "user_item_matrix = sparse.csr_matrix((data, (rows, cols)), shape=(len(user_id_map), len(item_id_map)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_random(user_idx, user_items, N=10):\n",
    "    seen_items = set(user_items.indices)\n",
    "    all_items = set(range(user_item_matrix.shape[1]))\n",
    "    unseen_items = list(all_items - seen_items)\n",
    "\n",
    "    if len(unseen_items) < N:\n",
    "        N = len(unseen_items)\n",
    "\n",
    "    recommended_items = random.sample(unseen_items, N)\n",
    "    return recommended_items\n",
    "\n",
    "def show_recommendations_random(user_id, n):\n",
    "    user_idx = user_id_map[user_id]\n",
    "    user_items = user_item_matrix[user_idx]\n",
    "    rec = recommend_random(user_idx, user_items, N=n)\n",
    "    return df_items[df_items['anime_id'].isin([reverse_item_id_map[i] for i in rec])]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514                               Slayers Evolution-R\n",
      "1524     Detective Conan Bonus File: Fantasista Flower\n",
      "1953                                  The Sky Crawlers\n",
      "2443                                 Fushigi Yuugi OVA\n",
      "2830                                    Buki yo Saraba\n",
      "2941                            Deadman Wonderland OVA\n",
      "3043                             Arslan Senki (TV) OVA\n",
      "5566                                       Sekkou Boys\n",
      "11369                                           Garden\n",
      "12272                                        Nudl Nude\n",
      "Name: name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(show_recommendations_random(user_id=20881, n=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_items_test = df_test.groupby('user_id')['item_id'].apply(list).to_dict()\n",
    "recommendations_random = {}\n",
    "\n",
    "for user_id in user_items_test.keys():\n",
    "    if user_id in user_id_map:\n",
    "        user_idx = user_id_map[user_id]\n",
    "        user_items = user_item_matrix[user_idx]\n",
    "        recs = recommend_random(user_idx, user_items, N=10)\n",
    "        recommendations_random[user_id] = [reverse_item_id_map[i] for i in recs]\n",
    "\n",
    "def evaluate_model(recommendations, ground_truth, n=10):\n",
    "    \n",
    "    map_scores = []\n",
    "    ndcg_scores = []\n",
    "    recall_scores = []\n",
    "\n",
    "    for user, rec_items in recommendations.items():\n",
    "        if user not in ground_truth:\n",
    "            continue\n",
    "\n",
    "        relevant_items = set(ground_truth[user])\n",
    "        hits = [1 if item in relevant_items else 0 for item in rec_items]\n",
    "\n",
    "        # MAP\n",
    "        if any(hits):\n",
    "            precisions = [np.mean(hits[:i + 1]) for i in range(len(hits)) if hits[i] == 1]\n",
    "            map_score = np.mean(precisions) if precisions else 0\n",
    "        else:\n",
    "            map_score = 0\n",
    "\n",
    "        # NDCG\n",
    "        dcg = sum([hit / math.log2(idx + 2) for idx, hit in enumerate(hits)])\n",
    "        idcg = sum([1.0 / math.log2(i + 2) for i in range(min(len(relevant_items), n))])\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "        # Recall\n",
    "        recall = sum(hits) / len(relevant_items) if relevant_items else 0\n",
    "\n",
    "        map_scores.append(map_score)\n",
    "        ndcg_scores.append(ndcg)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "    return np.mean(map_scores), np.mean(ndcg_scores), np.mean(recall_scores)\n",
    "\n",
    "def diversity(recommendations):\n",
    "    all_recs = [item for recs in recommendations.values() for item in recs]\n",
    "    unique_items = set(all_recs)\n",
    "    total_recs = len(all_recs)\n",
    "    return len(unique_items) / total_recs if total_recs > 0 else 0\n",
    "\n",
    "def calculate_novelty(recommendations, train_df=df_train):\n",
    "    item_counts = Counter(train_df['item_id'])\n",
    "    total_interactions = sum(item_counts.values())\n",
    "\n",
    "    novelty_scores = []\n",
    "    for user, rec_items in recommendations.items():\n",
    "        for item in rec_items:\n",
    "            count = item_counts.get(item, 1)\n",
    "            prob = count / total_interactions\n",
    "            novelty = -math.log(prob)\n",
    "            novelty_scores.append(novelty)\n",
    "\n",
    "    return np.mean(novelty_scores) if novelty_scores else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.0012\n",
      "NDCG@10: 0.0018\n",
      "Recall@10: 0.0041\n",
      "Diversity: 0.1903\n",
      "Novelty: 9.0035\n"
     ]
    }
   ],
   "source": [
    "map_random, ndcg_random, recall_random = evaluate_model(recommendations_random, user_items_test, n=10)\n",
    "div_random = diversity(recommendations_random)\n",
    "nov_random = calculate_novelty(recommendations_random)\n",
    "\n",
    "print(f\"MAP@10: {map_random:.4f}\")\n",
    "print(f\"NDCG@10: {ndcg_random:.4f}\")\n",
    "print(f\"Recall@10: {recall_random:.4f}\")\n",
    "print(f\"Diversity: {div_random:.4f}\")\n",
    "print(f\"Novelty: {nov_random:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
