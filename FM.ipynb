{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5634c487",
   "metadata": {},
   "source": [
    "# FM sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248d3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lightfm #una sola vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d683d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.10 (default, Jul 29 2024, 17:02:10) \n",
      "[GCC 9.4.0]\n",
      "LightFM version: 1.17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightfm\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import cross_validation\n",
    "from lightfm.evaluation import precision_at_k as lightfm_prec_at_k\n",
    "from lightfm.evaluation import recall_at_k as lightfm_recall_at_k\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "from collections import defaultdict\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"LightFM version: {}\".format(lightfm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb992298",
   "metadata": {},
   "source": [
    "# LOAD csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c348636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/train.csv\")\n",
    "df_validation = pd.read_csv(\"dataset/validation.csv\")\n",
    "df_genres = pd.read_csv(\"dataset/anime_genres.csv\")\n",
    "\n",
    "df_full = df_train[df_train['rating'] != -1].copy()\n",
    "df_validation = df_validation[df_validation['rating'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccb8cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.data import Dataset\n",
    "\n",
    "# Dataset with features, anime genres = item features\n",
    "dataset = Dataset()\n",
    "dataset.fit(df_full['user_id'], df_full['anime_id'])\n",
    "dataset.fit_partial(items=df_genres['anime_id'], item_features=df_genres.columns[1:].tolist())\n",
    "\n",
    "(interactions_full, _) = dataset.build_interactions([\n",
    "    (row['user_id'], row['anime_id']) for _, row in df_full.iterrows()\n",
    "])\n",
    "\n",
    "anime_features = []\n",
    "for _, row in df_genres.iterrows():\n",
    "    genres = [genre for genre in df_genres.columns[1:] if row[genre] == 1]\n",
    "    anime_features.append((row['anime_id'], genres))\n",
    "\n",
    "item_features_full = dataset.build_item_features(anime_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830dd8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f30ecb3be50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training with warp as the loss function and arbitrary first parameters\n",
    "model_full = LightFM(loss='warp', no_components=30, random_state=42)\n",
    "model_full.fit(interactions_full, item_features=item_features_full, epochs=10, num_threads=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59508eb2",
   "metadata": {},
   "source": [
    "# Evaluation on df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab1498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1497/1497 [00:27<00:00, 54.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.0077\n",
      "MAP@10: 0.0049\n",
      "nDCG@10: 0.1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# mapping\n",
    "user_id_map = dataset.mapping()[0]\n",
    "item_id_map = dataset.mapping()[2]\n",
    "reverse_user_map = {v: k for k, v in user_id_map.items()}\n",
    "reverse_item_map = {v: k for k, v in item_id_map.items()}\n",
    "\n",
    "# filter \n",
    "valid_users = df_validation['user_id'].isin(df_full['user_id'])\n",
    "valid_items = df_validation['anime_id'].isin(df_full['anime_id'])\n",
    "df_val_filtered = df_validation[valid_users & valid_items]\n",
    "\n",
    "(interactions_val, _) = dataset.build_interactions([\n",
    "    (row['user_id'], row['anime_id']) for _, row in df_val_filtered.iterrows()\n",
    "])\n",
    "\n",
    "val_truth = defaultdict(set)\n",
    "for _, row in df_val_filtered.iterrows():\n",
    "    val_truth[user_id_map[row['user_id']]].add(item_id_map[row['anime_id']])\n",
    "\n",
    "recall_list, map_list, ndcg_list = [], [], []\n",
    "k = 10\n",
    "\n",
    "for user in tqdm(val_truth):\n",
    "    relevant = np.zeros(len(item_id_map))\n",
    "    for item in val_truth[user]:\n",
    "        relevant[item] = 1\n",
    "\n",
    "    known_items = interactions_full.tocsr()[user].nonzero()[1]\n",
    "    preds = model_full.predict(user, np.arange(len(item_id_map)), item_features=item_features_full)\n",
    "    preds[known_items] = -np.inf\n",
    "\n",
    "    preds_safe = np.copy(preds)\n",
    "    preds_safe[~np.isfinite(preds_safe)] = -1e9\n",
    "\n",
    "    top_k = np.argsort(-preds)[:k]\n",
    "    hits = [1 if i in val_truth[user] else 0 for i in top_k]\n",
    "\n",
    "    recall_list.append(np.sum(hits) / len(val_truth[user]))\n",
    "    map_list.append(average_precision_score(relevant, preds_safe))\n",
    "    ndcg_list.append(ndcg_score([relevant], [preds_safe]))\n",
    "\n",
    "print(f\"Recall@{k}: {np.mean(recall_list):.4f}\")\n",
    "print(f\"MAP@{k}: {np.mean(map_list):.4f}\")\n",
    "print(f\"nDCG@{k}: {np.mean(ndcg_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82399ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1497/1497 [00:29<00:00, 51.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity (prom.): 8.00\n",
      "Novelty (prom.): 7.2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "anime_counts = df_full['anime_id'].value_counts().to_dict()\n",
    "total_users = df_full['user_id'].nunique()\n",
    "anime_popularity = {\n",
    "    item_id_map[aid]: count / total_users\n",
    "    for aid, count in anime_counts.items()\n",
    "    if aid in item_id_map\n",
    "}\n",
    "\n",
    "diversity_list = []\n",
    "novelty_list = []\n",
    "\n",
    "for user in tqdm(val_truth):\n",
    "    known_items = interactions_full.tocsr()[user].nonzero()[1]\n",
    "    preds = model_full.predict(user, np.arange(len(item_id_map)), item_features=item_features_full)\n",
    "    preds[known_items] = -np.inf\n",
    "    top_k = np.argsort(-preds)[:k]\n",
    "\n",
    "    # Diversity\n",
    "    genres_reco = set()\n",
    "    for item in top_k:\n",
    "        anime_id = reverse_item_map[item]\n",
    "        anime_row = df_genres[df_genres['anime_id'] == anime_id]\n",
    "        if not anime_row.empty:\n",
    "            for col in df_genres.columns[1:]:\n",
    "                if anime_row.iloc[0][col] == 1:\n",
    "                    genres_reco.add(col)\n",
    "    diversity_list.append(len(genres_reco))\n",
    "\n",
    "    # Novelty\n",
    "    novelty = 0\n",
    "    for item in top_k:\n",
    "        pop = anime_popularity.get(item, 1e-6)\n",
    "        novelty += log(1 / pop)\n",
    "    novelty_list.append(novelty / k)\n",
    "\n",
    "print(f\"Diversity (prom.): {np.mean(diversity_list):.2f}\")\n",
    "print(f\"Novelty (prom.): {np.mean(novelty_list):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t1recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
