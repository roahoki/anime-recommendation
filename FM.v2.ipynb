{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5634c487",
   "metadata": {},
   "source": [
    "# FM sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lightfm #una sola vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d683d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.10 (default, Jul 29 2024, 17:02:10) \n",
      "[GCC 9.4.0]\n",
      "LightFM version: 1.17\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightfm\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import cross_validation\n",
    "from lightfm.evaluation import precision_at_k as lightfm_prec_at_k\n",
    "from lightfm.evaluation import recall_at_k as lightfm_recall_at_k\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"LightFM version: {}\".format(lightfm.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb992298",
   "metadata": {},
   "source": [
    "# LOAD csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c348636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"dataset/train.csv\")\n",
    "df_validation = pd.read_csv(\"dataset/validation.csv\")\n",
    "df_genres = pd.read_csv(\"dataset/anime_genres.csv\")\n",
    "\n",
    "# Ignore the -1's ratings\n",
    "df_train_implicit = df_train[df_train['rating'] != -1].copy()\n",
    "\n",
    "# Sample\n",
    "df_train_sample = df_train_implicit.sample(5000, random_state=42)\n",
    "\n",
    "# Ignore the -1's inside the validation df\n",
    "df_validation = df_validation[df_validation['rating'] != -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb8cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.data import Dataset\n",
    "\n",
    "# Dataset with features, anime genres = item features\n",
    "dataset = Dataset()\n",
    "dataset.fit(df_train_sample['user_id'], df_train_sample['anime_id'])\n",
    "dataset.fit_partial(items=df_genres['anime_id'], item_features=df_genres.columns[1:].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61e0785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implicit interactions\n",
    "(interactions, _) = dataset.build_interactions([\n",
    "    (row['user_id'], row['anime_id']) for _, row in df_train_sample.iterrows()\n",
    "])\n",
    "\n",
    "# anime features\n",
    "anime_features = []\n",
    "for _, row in df_genres.iterrows():\n",
    "    genres = [genre for genre in df_genres.columns[1:] if row[genre] == 1]\n",
    "    anime_features.append((row['anime_id'], genres))\n",
    "\n",
    "item_features = dataset.build_item_features(anime_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "830dd8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f049449dc70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "# training with warp as the loss function and arbitrary first parameters\n",
    "model = LightFM(loss='warp', no_components=30, random_state=42)\n",
    "model.fit(interactions, item_features=item_features, epochs=10, num_threads=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45ee2420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10 (train sample): 0.0389\n"
     ]
    }
   ],
   "source": [
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "precision = precision_at_k(model, interactions, item_features=item_features, k=10).mean()\n",
    "print(f\"Precision@10 (train sample): {precision:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59508eb2",
   "metadata": {},
   "source": [
    "# Evaluation on df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab1498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid users and items inside the sample\n",
    "valid_users = df_validation['user_id'].isin(df_train_sample['user_id'])\n",
    "valid_items = df_validation['anime_id'].isin(df_train_sample['anime_id'])\n",
    "df_val_filtered = df_validation[valid_users & valid_items]\n",
    "\n",
    "# interactions\n",
    "(interactions_val, _) = dataset.build_interactions([\n",
    "    (row['user_id'], row['anime_id']) for _, row in df_val_filtered.iterrows()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59f8c043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [00:07<00:00, 56.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@10: 0.0075\n",
      "MAP@10: 0.0050\n",
      "nDCG@10: 0.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import ndcg_score, average_precision_score\n",
    "\n",
    "def get_recommendations(model, user_id, known_items, item_features, N=10):\n",
    "    n_users, n_items = interactions.shape\n",
    "    scores = model.predict(user_id, np.arange(n_items), item_features=item_features)\n",
    "    scores[known_items] = -np.inf  # do not recommend already watched\n",
    "    top_items = np.argsort(-scores)[:N]\n",
    "    return top_items\n",
    "\n",
    "def get_user_index_map():\n",
    "    user_map, _, _ = dataset.mapping()[0]\n",
    "    return {v: k for k, v in user_map.items()}\n",
    "\n",
    "def get_item_index_map():\n",
    "    item_map, _, _ = dataset.mapping()[2]\n",
    "    return {v: k for k, v in item_map.items()}\n",
    "\n",
    "# structures \n",
    "user_id_map = dataset.mapping()[0]\n",
    "item_id_map = dataset.mapping()[2]\n",
    "reverse_user_map = {v: k for k, v in user_id_map.items()}\n",
    "reverse_item_map = {v: k for k, v in item_id_map.items()}\n",
    "\n",
    "# ground truth per user\n",
    "from collections import defaultdict\n",
    "\n",
    "val_truth = defaultdict(set)\n",
    "for _, row in df_val_filtered.iterrows():\n",
    "    val_truth[user_id_map[row['user_id']]].add(item_id_map[row['anime_id']])\n",
    "\n",
    "# metrics\n",
    "recall_list, map_list, ndcg_list = [], [], []\n",
    "k = 10\n",
    "\n",
    "for user in tqdm(val_truth):\n",
    "    relevant = np.zeros(len(item_id_map))\n",
    "    for item in val_truth[user]:\n",
    "        relevant[item] = 1\n",
    "\n",
    "    # get recommendations\n",
    "    known_items = interactions.tocsr()[user].nonzero()[1]\n",
    "    preds = model.predict(user, np.arange(len(item_id_map)), item_features=item_features)\n",
    "    preds[known_items] = -np.inf\n",
    "    top_k = np.argsort(-preds)[:k]\n",
    "\n",
    "    # binary ground truth for top_k\n",
    "    hits = [1 if i in val_truth[user] else 0 for i in top_k]\n",
    "    recall_list.append(np.sum(hits) / len(val_truth[user]))\n",
    "    # Ensure a float number instead of minus infinite\n",
    "    preds_safe = np.copy(preds)\n",
    "    preds_safe[~np.isfinite(preds_safe)] = -1e9\n",
    "\n",
    "    map_list.append(average_precision_score(relevant, preds_safe))\n",
    "    ndcg_list.append(ndcg_score([relevant], [preds_safe]))\n",
    "\n",
    "\n",
    "print(f\"Recall@{k}: {np.mean(recall_list):.4f}\")\n",
    "print(f\"MAP@{k}: {np.mean(map_list):.4f}\")\n",
    "print(f\"nDCG@{k}: {np.mean(ndcg_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f82399ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 401/401 [00:07<00:00, 56.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity (prom.): 6.16\n",
      "Novelty (prom.): 8.6253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "\n",
    "# popularity (for novelty)\n",
    "anime_counts = df_train_sample['anime_id'].value_counts().to_dict()\n",
    "total_users = df_train_sample['user_id'].nunique()\n",
    "anime_popularity = {\n",
    "    item_id_map[aid]: count / total_users\n",
    "    for aid, count in anime_counts.items()\n",
    "    if aid in item_id_map\n",
    "}\n",
    "\n",
    "# calc\n",
    "diversity_list = []\n",
    "novelty_list = []\n",
    "\n",
    "for user in tqdm(val_truth):\n",
    "    known_items = interactions.tocsr()[user].nonzero()[1]\n",
    "    preds = model.predict(user, np.arange(len(item_id_map)), item_features=item_features)\n",
    "    preds[known_items] = -np.inf\n",
    "    top_k = np.argsort(-preds)[:k]\n",
    "\n",
    "    # diversity (unique genres)\n",
    "    genres_reco = set()\n",
    "    for item in top_k:\n",
    "        anime_id = reverse_item_map[item]\n",
    "        anime_row = df_genres[df_genres['anime_id'] == anime_id]\n",
    "        if not anime_row.empty:\n",
    "            for col in df_genres.columns[1:]:\n",
    "                if anime_row.iloc[0][col] == 1:\n",
    "                    genres_reco.add(col)\n",
    "    diversity_list.append(len(genres_reco))\n",
    "\n",
    "    # Novelty\n",
    "    novelty = 0\n",
    "    for item in top_k:\n",
    "        pop = anime_popularity.get(item, 1e-6)\n",
    "        novelty += log(1 / pop)\n",
    "    novelty_list.append(novelty / k)\n",
    "\n",
    "print(f\"Diversity (prom.): {np.mean(diversity_list):.2f}\")\n",
    "print(f\"Novelty (prom.): {np.mean(novelty_list):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903411a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete dataset\n",
    "df_full = df_train[df_train['rating'] != -1].copy()\n",
    "\n",
    "# dataset modified to use in lightFM\n",
    "dataset = Dataset()\n",
    "dataset.fit(df_full['user_id'], df_full['anime_id'])\n",
    "dataset.fit_partial(items=df_genres['anime_id'], item_features=df_genres.columns[1:].tolist())\n",
    "\n",
    "# interactions\n",
    "(interactions_full, _) = dataset.build_interactions([\n",
    "    (row['user_id'], row['anime_id']) for _, row in df_full.iterrows()\n",
    "])\n",
    "\n",
    "# features\n",
    "anime_features = []\n",
    "for _, row in df_genres.iterrows():\n",
    "    genres = [genre for genre in df_genres.columns[1:] if row[genre] == 1]\n",
    "    anime_features.append((row['anime_id'], genres))\n",
    "\n",
    "item_features_full = dataset.build_item_features(anime_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e0c6954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f0491b7f490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full = LightFM(loss='warp', no_components=30, random_state=42)\n",
    "model_full.fit(interactions_full, item_features=item_features_full, epochs=10, num_threads=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t1recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
